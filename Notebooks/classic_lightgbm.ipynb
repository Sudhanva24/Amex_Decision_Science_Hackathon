{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d992b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa26379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_parquet('../Data/small_train_engineered.parquet')\n",
    "val=pd.read_parquet('../Data/small_val_engineered.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df90d156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id2                                 category\n",
       "id3                                 category\n",
       "id4                           datetime64[ns]\n",
       "id5                           datetime64[ns]\n",
       "y                                       int8\n",
       "                                   ...      \n",
       "num_offer_categories                   int64\n",
       "sub_category                        category\n",
       "num_sub_categories                     int64\n",
       "previous_offer_category             category\n",
       "previous_suboffer_category          category\n",
       "Length: 240, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae586fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- YOUR HACKATHON METRIC FUNCTION ---\n",
    "def map_at_k(y_true, y_pred_scores, group_ids, k=7):\n",
    "    \"\"\"\n",
    "    Calculates the Mean Average Precision at k.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'group': group_ids, 'y_true': y_true, 'score': y_pred_scores})\n",
    "    \n",
    "    average_precisions = []\n",
    "    total_relevant_per_group = df[df['y_true'] == 1].groupby('group')['y_true'].count()\n",
    "\n",
    "    for group_id, group_df in df.groupby('group'):\n",
    "        total_relevant = total_relevant_per_group.get(group_id, 0)\n",
    "        if total_relevant == 0:\n",
    "            continue\n",
    "\n",
    "        group_df = group_df.sort_values('score', ascending=False).head(k)\n",
    "        \n",
    "        hits = 0\n",
    "        precision_sum = 0.0\n",
    "        \n",
    "        for i, row in enumerate(group_df.itertuples(index=False)):\n",
    "            rank = i + 1\n",
    "            if row.y_true == 1:\n",
    "                hits += 1\n",
    "                precision_at_k = hits / rank\n",
    "                precision_sum += precision_at_k\n",
    "        \n",
    "        ap = precision_sum / total_relevant\n",
    "        average_precisions.append(ap)\n",
    "\n",
    "    return np.mean(average_precisions) if average_precisions else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7850c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- WRAPPER FUNCTION FOR LIGHTGBM ---\n",
    "def lgb_map_at_k_factory(group_ids, k=7):\n",
    "    \"\"\"\n",
    "    This factory creates the metric function LightGBM needs.\n",
    "    \"\"\"\n",
    "    def lgb_map_at_k(y_true, y_pred):\n",
    "        # Call your main metric function with all required parts\n",
    "        score = map_at_k(\n",
    "            y_true=y_true,\n",
    "            y_pred_scores=y_pred,\n",
    "            group_ids=group_ids,\n",
    "            k=k\n",
    "        )\n",
    "        # The return format is (metric_name, value, is_higher_better)\n",
    "        return 'map@k', score, True\n",
    "        \n",
    "    return lgb_map_at_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bd6d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- DATA PREPARATION (Assuming it's already done) ---\n",
    "TARGET = 'y'\n",
    "FEATURES = [col for col in train.columns if col not in [TARGET, 'id2', 'id3','id4','id5']]\n",
    "\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "X_val = val[FEATURES]\n",
    "y_val = val[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6edfb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- MODEL TRAINING ---\n",
    "# Create the specific metric function for our validation set using the factory\n",
    "eval_metric_function = lgb_map_at_k_factory(group_ids=val['id2'], k=7)\n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    is_unbalance=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d0c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8907, number of negative: 115471\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 39911\n",
      "[LightGBM] [Info] Number of data points in the train set: 124378, number of used features: 233\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.071612 -> initscore=-2.562182\n",
      "[LightGBM] [Info] Start training from score -2.562182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7w/qs77cz_11630n9gydm61vjpc0000gn/T/ipykernel_7088/424330085.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  total_relevant_per_group = df[df['y_true'] == 1].groupby('group')['y_true'].count()\n",
      "/var/folders/7w/qs77cz_11630n9gydm61vjpc0000gn/T/ipykernel_7088/424330085.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for group_id, group_df in df.groupby('group'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's binary_logloss: 0.128495\tvalid_0's map@k: 0.574902\n",
      "\n",
      "Training complete!\n",
      "Best MAP@k on validation set: 0.5749\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model using your exact metric for evaluation\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=eval_metric_function,\n",
    "    callbacks=[lgb.early_stopping(50, verbose=True)]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Best MAP@k on validation set: {model.best_score_['valid_0']['map@k']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8069d6",
   "metadata": {},
   "source": [
    "# Trying with the new Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b4d7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=pd.read_parquet('../Data/small_train_feature_engineered_2.parquet',engine='pyarrow')\n",
    "val2=pd.read_parquet('../Data/small_val_feature_engineered_2.parquet',engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ab1fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATA PREPARATION (Assuming it's already done) ---\n",
    "TARGET2 = 'y'\n",
    "FEATURES2 = [col for col in train2.columns if col not in [TARGET2, 'id2', 'id3','id4','id5']]\n",
    "\n",
    "X_train_2 = train2[FEATURES2]\n",
    "y_train_2 = train2[TARGET2]\n",
    "X_val_2 = val2[FEATURES2]\n",
    "y_val_2 = val2[TARGET2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb74a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- MODEL TRAINING ---\n",
    "# Create the specific metric function for our validation set using the factory\n",
    "eval_metric_function_2 = lgb_map_at_k_factory(group_ids=val2['id2'], k=7)\n",
    "\n",
    "model2 = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    is_unbalance=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "749c2151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8907, number of negative: 115471\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40949\n",
      "[LightGBM] [Info] Number of data points in the train set: 124378, number of used features: 222\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.071612 -> initscore=-2.562182\n",
      "[LightGBM] [Info] Start training from score -2.562182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7w/qs77cz_11630n9gydm61vjpc0000gn/T/ipykernel_7088/424330085.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  total_relevant_per_group = df[df['y_true'] == 1].groupby('group')['y_true'].count()\n",
      "/var/folders/7w/qs77cz_11630n9gydm61vjpc0000gn/T/ipykernel_7088/424330085.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for group_id, group_df in df.groupby('group'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's binary_logloss: 0.0746879\tvalid_0's map@k: 0.626657\n",
      "\n",
      "Training complete!\n",
      "Best MAP@k on validation set: 0.6267\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model using your exact metric for evaluation\n",
    "model2.fit(\n",
    "    X_train_2, y_train_2,\n",
    "    eval_set=[(X_val_2, y_val_2)],\n",
    "    eval_metric=eval_metric_function,\n",
    "    callbacks=[lgb.early_stopping(50, verbose=True)]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Best MAP@k on validation set: {model2.best_score_['valid_0']['map@k']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18688d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
